{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6773a9ce",
   "metadata": {},
   "source": [
    "Role of kernel size :\n",
    "\n",
    "Deep neural networks, more concretely convolutional neural networks (CNN), are basically a stack of layers which are defined by the action of a number of filters on the input. Those filters are usually called kernels.\n",
    "\n",
    "For example, the kernels in the convolutional layer, are the convolutional filters. Actually no convolution is performed, but a cross-correlation. The kernel size here refers to the widthxheight of the filter mask.\n",
    "\n",
    "The max pooling layer, for example, returns the pixel with maximum value from a set of pixels within a mask (kernel). That kernel is swept across the input, subsampling it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e6f592",
   "metadata": {},
   "source": [
    "Activation Function : An Activation Function decides whether a neuron should be activated or not. This means that it will decide whether the neuronâ€™s input to the network is important or not in the process of prediction using simpler mathematical operations. \n",
    "The role of the Activation Function is to derive output from a set of input values fed to a node (or a layer).\n",
    "\n",
    "Some functions are :\n",
    "1. Binary Step Function\n",
    "2. Linear Function\n",
    "3. Sigmoid\n",
    "4. Tanh\n",
    "5. ReLU\n",
    "6. Leaky ReLU\n",
    "7. Parameterised ReLU\n",
    "8. Exponential Linear Unit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a501e1",
   "metadata": {},
   "source": [
    "Classification using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b4b6f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# to calculate accuracy\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a942ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 23s 2us/step\n"
     ]
    }
   ],
   "source": [
    "# loading the dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# building the input vector from the 28x28 pixels\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f0159cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the data to help with the training\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7388c149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (60000,)\n",
      "Shape after one-hot encoding:  (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding using keras' numpy-related utilities\n",
    "n_classes = 10\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec870e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 41s 83ms/step - loss: 0.1963 - accuracy: 0.9438 - val_loss: 0.0816 - val_accuracy: 0.9738\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 40s 85ms/step - loss: 0.0599 - accuracy: 0.9816 - val_loss: 0.0605 - val_accuracy: 0.9804\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 43s 91ms/step - loss: 0.0365 - accuracy: 0.9890 - val_loss: 0.0581 - val_accuracy: 0.9819\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.0228 - accuracy: 0.9930 - val_loss: 0.0528 - val_accuracy: 0.9829\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 43s 91ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.0476 - val_accuracy: 0.9846\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 43s 91ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.0599 - val_accuracy: 0.9829\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 43s 91ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.0585 - val_accuracy: 0.9845\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0595 - val_accuracy: 0.9841\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 51s 109ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0707 - val_accuracy: 0.9823\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 49s 105ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.0657 - val_accuracy: 0.9845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x252f0b3bd30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "# convolutional layer\n",
    "model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPool2D(pool_size=(1,1)))\n",
    "# flatten output of conv\n",
    "model.add(Flatten())\n",
    "# hidden layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "# output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# training the model for 10 epochs\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b80ea89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.06570284068584442, 0.984499990940094]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435a17f7",
   "metadata": {},
   "source": [
    "### Test Accuracy is 98.44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64a9f63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 39s 79ms/step - loss: nan - accuracy: 0.1477 - val_loss: nan - val_accuracy: 0.0980\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 37s 78ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 37s 80ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 38s 81ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 67s 144ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 63s 134ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 37s 79ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 37s 79ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 37s 79ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25283c43580>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "# convolutional layer\n",
    "model.add(Conv2D(25, kernel_size=(6,6), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPool2D(pool_size=(1,1)))\n",
    "# flatten output of conv\n",
    "model.add(Flatten())\n",
    "# hidden layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "# output layer\n",
    "model.add(Dense(10, activation='relu'))\n",
    "\n",
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# training the model for 10 epochs\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f694a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan, 0.09799999743700027]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4c6b74",
   "metadata": {},
   "source": [
    "### Test Accuracy is 09.79 which is very low"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113d38ad",
   "metadata": {},
   "source": [
    "Here the dimensions of kernel are changed to (6,6) which have reduced accuracy. Basic reason of not using (even numbers) X (even numbers) layers is because those layers do not have a \"center\". Having a \"center\" pixel (as in a 3X3 configuration) is vey useful for max and average pooling. it's much more convenient for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd0b3dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 41s 84ms/step - loss: 8.0494 - accuracy: 0.1123 - val_loss: 7.7141 - val_accuracy: 0.0710\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 39s 83ms/step - loss: nan - accuracy: 0.0928 - val_loss: nan - val_accuracy: 0.0980\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 39s 84ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 39s 84ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 40s 84ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 40s 85ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 40s 85ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 40s 85ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 54s 116ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 40s 84ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2528856f700>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# convolutional layer\n",
    "model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPool2D(pool_size=(1,1)))\n",
    "# flatten output of conv\n",
    "model.add(Flatten())\n",
    "# hidden layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "# output layer\n",
    "model.add(Dense(10, activation='tanh'))\n",
    "\n",
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# training the model for 10 epochs\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f45bbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan, 0.09799999743700027]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17034ed9",
   "metadata": {},
   "source": [
    "Using tanh activation function for output layer here reduced the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12cd8982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 44s 89ms/step - loss: 0.1973 - accuracy: 0.9426 - val_loss: 0.0802 - val_accuracy: 0.9755\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.0592 - accuracy: 0.9824 - val_loss: 0.0558 - val_accuracy: 0.9814\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.0355 - accuracy: 0.9891 - val_loss: 0.0511 - val_accuracy: 0.9827\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.0233 - accuracy: 0.9928 - val_loss: 0.0525 - val_accuracy: 0.9829\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.0513 - val_accuracy: 0.9847\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.0098 - accuracy: 0.9973 - val_loss: 0.0585 - val_accuracy: 0.9837\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.0529 - val_accuracy: 0.9853\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0622 - val_accuracy: 0.9834\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.0599 - val_accuracy: 0.9844\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.0672 - val_accuracy: 0.9819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2528871bdc0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# convolutional layer\n",
    "model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPool2D(pool_size=(1,1)))\n",
    "# flatten output of conv\n",
    "model.add(Flatten())\n",
    "# hidden layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "# output layer\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "\n",
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# training the model for 10 epochs\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0a5307a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.06718787550926208, 0.9818999767303467]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ad7041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab29ebd3",
   "metadata": {},
   "source": [
    "Using sigmoid activation function for output layer here accuracy is good ans closer to that of softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bdcaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# create a new generator\n",
    "imagegen = ImageDataGenerator()\n",
    "# load train data\n",
    "train = imagegen.flow_from_directory(\"imagenette2/train/\", class_mode=\"categorical\", shuffle=False, batch_size=128, target_size=(224, 224))\n",
    "# load val data\n",
    "val = imagegen.flow_from_directory(\"imagenette2/val/\", class_mode=\"categorical\", shuffle=False, batch_size=128, target_size=(224, 224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6291cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, InputLayer, BatchNormalization, Dropout\n",
    "\n",
    "# build a sequential model\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(224, 224, 3)))\n",
    "\n",
    "# 1st conv block\n",
    "model.add(Conv2D(25, (5, 5), activation='relu', strides=(1, 1), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "# 2nd conv block\n",
    "model.add(Conv2D(50, (5, 5), activation='relu', strides=(2, 2), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "# 3rd conv block\n",
    "model.add(Conv2D(70, (3, 3), activation='relu', strides=(2, 2), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "# ANN block\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "# output layer\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "# fit on data for 30 epochs\n",
    "model.fit_generator(train, epochs=30, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1557c66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "# include top should be False to remove the softmax layer\n",
    "pretrained_model = VGG16(include_top=False, weights='imagenet')\n",
    "pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d696644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "# extract train and val features\n",
    "vgg_features_train = pretrained_model.predict(train)\n",
    "vgg_features_val = pretrained_model.predict(val)\n",
    "# OHE target column\n",
    "train_target = to_categorical(train.labels)\n",
    "val_target = to_categorical(val.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a414d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Flatten(input_shape=(7,7,512)))\n",
    "model2.add(Dense(100, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model2.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model2.summary()\n",
    "\n",
    "# train model using features generated from VGG16 model\n",
    "model2.fit(vgg_features_train, train_target, epochs=50, batch_size=128, validation_data=(vgg_features_val, val_target))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
